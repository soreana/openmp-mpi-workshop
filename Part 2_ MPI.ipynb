{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a56feb-93ed-48f4-8123-4323f420b848",
   "metadata": {},
   "source": [
    "### OpenMP and MPI Interactive Tutorial\n",
    "\n",
    "## Part 2: MPI\n",
    "\n",
    "### 7. Introduction to MPI\n",
    "\n",
    "#### What is MPI?\n",
    "MPI (Message Passing Interface) is a standardized and portable message-passing system designed for high-performance computing (HPC) applications running on distributed-memory systems. It enables processes to communicate with each other by sending and receiving messages.\n",
    "\n",
    "#### Key Features of MPI:\n",
    "- Designed for distributed-memory parallel computing.\n",
    "- Provides communication between processes running on different nodes.\n",
    "- Offers both point-to-point and collective communication.\n",
    "- Highly scalable for large-scale parallel applications.\n",
    "- Portable across different computing architectures.\n",
    "\n",
    "#### MPI vs OpenMP\n",
    "| Feature        | MPI (Message Passing Interface) | OpenMP (Open Multi-Processing) |\n",
    "|---------------|--------------------------------|--------------------------------|\n",
    "| Memory Model  | Distributed                     | Shared                         |\n",
    "| Communication | Explicit message passing        | Implicit (shared memory)       |\n",
    "| Scalability   | Scales across multiple nodes    | Limited to a single node       |\n",
    "| Synchronization | Explicit                       | Implicit                        |\n",
    "\n",
    "#### MPI Implementations\n",
    "Several implementations of MPI are widely used, including:\n",
    "- **MPICH** (Argonne National Laboratory)\n",
    "- **OpenMPI** (Open source, supports multiple platforms)\n",
    "- **Intel MPI** (Optimized for Intel architectures)\n",
    "- **MVAPICH** (Optimized for high-performance networks)\n",
    "\n",
    "#### Installing MPI\n",
    "To use MPI, you need an MPI implementation installed on your system.\n",
    "\n",
    "**For Ubuntu/Linux:**\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt install mpich\n",
    "```\n",
    "\n",
    "**For macOS (using Homebrew):**\n",
    "```bash\n",
    "brew install mpich\n",
    "```\n",
    "\n",
    "**For Windows:**\n",
    "- Use Windows Subsystem for Linux (WSL) and install MPI as shown above.\n",
    "- Alternatively, install Microsoft MPI (MS-MPI).\n",
    "\n",
    "#### Running an MPI Program\n",
    "MPI programs typically run across multiple processes using `mpirun` or `mpiexec`.\n",
    "\n",
    "Example:\n",
    "```bash\n",
    "mpicc my_mpi_program.c -o my_mpi_program\n",
    "mpirun -np 4 ./my_mpi_program\n",
    "```\n",
    "\n",
    "In the next section, we will explore **Writing Your First MPI Program**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48fddd-18e5-4779-bd82-3fdebbc071fe",
   "metadata": {},
   "source": [
    "### 8. Writing Your First MPI Program\n",
    "\n",
    "MPI programs follow a standard structure consisting of initialization, communication, and finalization. Below, we will write a basic MPI program that demonstrates these concepts.\n",
    "\n",
    "#### Basic MPI Program (Hello World)\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    printf(\"Hello from process %d out of %d\\n\", rank, size);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "1. **MPI_Init**: Initializes the MPI environment.\n",
    "2. **MPI_Comm_rank**: Retrieves the rank (ID) of the current process.\n",
    "3. **MPI_Comm_size**: Determines the total number of processes.\n",
    "4. **MPI_Finalize**: Cleans up the MPI environment before program termination.\n",
    "\n",
    "#### Compiling and Running the MPI Program\n",
    "To compile the program, use an MPI compiler such as `mpicc`:\n",
    "```bash\n",
    "mpicc hello_mpi.c -o hello_mpi\n",
    "```\n",
    "Run the program with multiple processes:\n",
    "```bash\n",
    "mpirun -np 4 ./hello_mpi\n",
    "```\n",
    "Expected Output:\n",
    "```\n",
    "Hello from process 0 out of 4\n",
    "Hello from process 1 out of 4\n",
    "Hello from process 2 out of 4\n",
    "Hello from process 3 out of 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0493a544-ba07-43e5-8432-0d9bc21b14c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello_mpi.c\n"
     ]
    }
   ],
   "source": [
    "%%file hello_mpi.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    printf(\"Hello from process %d out of %d\\n\", rank, size);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6671e4-61db-4f30-b391-6bdf6714bbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from process 0 out of 2\n",
      "Hello from process 1 out of 2\n"
     ]
    }
   ],
   "source": [
    "!mpicc hello_mpi.c -o hello_mpi\n",
    "!mpiexec --allow-run-as-root -np 2 ./hello_mpi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f3bbf-9783-4558-9005-1229ac9e15cd",
   "metadata": {},
   "source": [
    "#### Exercise 1:\n",
    "Modify the Hello World program so that only the master process (rank 0) prints a message like:\n",
    "```\n",
    "Master process says: Hello, I manage 3 other processes!\n",
    "```\n",
    "\n",
    "This concludes the introduction to MPI programming. Next, we will explore **Point-to-Point Communication in MPI**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bbf3ee-d1fc-4ec8-a9e2-2cea2cf3c80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exercise_1.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_1.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    printf(\"TODO message only on master!\");\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045ec203-5380-4631-a194-1dc9a5b9f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO message only on master!TODO message only on master!"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_1.c -o exercise_1\n",
    "!mpiexec --allow-run-as-root -np 2 ./exercise_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2eef4-0734-4147-97bf-c9cbc66b4798",
   "metadata": {},
   "source": [
    "### 9. Point-to-Point Communication\n",
    "\n",
    "Point-to-point communication in MPI allows processes to send and receive messages directly. It is the fundamental method for communication in distributed-memory systems.\n",
    "\n",
    "#### 9.1 MPI Send and Receive\n",
    "The basic functions for point-to-point communication are:\n",
    "- `MPI_Send`: Sends a message from one process to another.\n",
    "- `MPI_Recv`: Receives a message sent from another process.\n",
    "\n",
    "#### Example: Basic Send and Receive\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        int data = 100;\n",
    "        MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
    "        printf(\"Process 0 sent data %d to process 1\\n\", data);\n",
    "    } else if (rank == 1) {\n",
    "        int received_data;\n",
    "        MPI_Recv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        printf(\"Process 1 received data %d from process 0\\n\", received_data);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "1. **Process 0** sends an integer (`data = 100`) to **Process 1** using `MPI_Send`.\n",
    "2. **Process 1** receives the data using `MPI_Recv`.\n",
    "3. The tag `0` is used to identify the message.\n",
    "4. `MPI_STATUS_IGNORE` is used if message status details are not required.\n",
    "\n",
    "#### Compiling and Running the Program\n",
    "```bash\n",
    "mpicc mpi_send_recv.c -o mpi_send_recv\n",
    "mpirun -np 2 ./mpi_send_recv\n",
    "```\n",
    "\n",
    "Expected Output:\n",
    "```\n",
    "Process 0 sent data 100 to process 1\n",
    "Process 1 received data 100 from process 0\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf3d92f6-2c97-485d-97f8-9c1444dfde38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mpi_send_recv.c\n"
     ]
    }
   ],
   "source": [
    "%%file mpi_send_recv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank); // Get rank of process\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size); // Get total number of processes\n",
    "\n",
    "    if (size < 2) {\n",
    "        if (rank == 0) {\n",
    "            printf(\"This program requires at least 2 processes!\\n\");\n",
    "        }\n",
    "        MPI_Finalize();\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    if (rank == 0) {\n",
    "        int data = 42;\n",
    "        printf(\"Process %d sending data %d to process 1\\n\", rank, data);\n",
    "        MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
    "    } \n",
    "    else if (rank == 1) {\n",
    "        int received_data;\n",
    "        MPI_Recv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        printf(\"Process %d received data %d from process 0\\n\", rank, received_data);\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da939e54-161a-4be6-bf5b-392d0dab68f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1 received data 42 from process 0\n",
      "Process 0 sending data 42 to process 1\n"
     ]
    }
   ],
   "source": [
    "!mpicc mpi_send_recv.c -o mpi_send_recv\n",
    "!mpiexec --allow-run-as-root -np 2 ./mpi_send_recv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d741cd-1143-4c66-aac6-84747e9c0147",
   "metadata": {},
   "source": [
    "#### 9.2 Blocking vs. Non-Blocking Communication\n",
    "MPI provides two types of send/receive operations:\n",
    "- **Blocking:** The sender waits until the message is received (`MPI_Send`, `MPI_Recv`).\n",
    "- **Non-Blocking:** The sender continues execution without waiting (`MPI_Isend`, `MPI_Irecv`).\n",
    "\n",
    "Example of Non-Blocking Communication:\n",
    "```c\n",
    "MPI_Request request;\n",
    "MPI_Isend(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, &request);\n",
    "```\n",
    "\n",
    "#### Exercise 2:\n",
    "Modify the program to:\n",
    "- Allow **Process 1** to send a message back to **Process 0**.\n",
    "- Use **non-blocking communication (`MPI_Isend` and `MPI_Irecv`)** instead of blocking calls.\n",
    "\n",
    "This concludes the introduction to **Point-to-Point Communication in MPI**. Next, we will explore **Collective Communication in MPI**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b0d80c6-2c0f-48d3-953e-64a5ac63e2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exercise_2.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_2.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    printf(\"TODO implement non-blocking\");\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b41036-c49a-4e2e-ac50-41dd3008f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO implement non-blockingTODO implement non-blocking"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_2.c -o exercise_2\n",
    "!mpiexec --allow-run-as-root -np 2 ./exercise_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad012ac2-c84d-4ce0-ad39-4ef0beeced7b",
   "metadata": {},
   "source": [
    "### 10. Collective Communication\n",
    "\n",
    "Collective communication in MPI allows multiple processes to communicate in a coordinated manner. These operations are optimized for efficiency and are useful for distributing data, gathering results, and synchronizing processes.\n",
    "\n",
    "#### 10.1 Common Collective Communication Operations\n",
    "MPI provides several collective communication functions:\n",
    "- **MPI_Bcast**: Broadcasts data from one process to all other processes.\n",
    "- **MPI_Scatter**: Distributes chunks of data from one process to all others.\n",
    "- **MPI_Gather**: Collects data from all processes to a single process.\n",
    "- **MPI_Reduce**: Combines values from all processes using an operation (e.g., sum, max, min).\n",
    "- **MPI_Allreduce**: Like `MPI_Reduce`, but results are distributed to all processes.\n",
    "- **MPI_Barrier**: Synchronizes all processes, ensuring they all reach the same execution point before proceeding.\n",
    "\n",
    "---\n",
    "### 10.2 Example: Broadcasting Data Using `MPI_Bcast`\n",
    "The `MPI_Bcast` function allows one process to send data to all others in the communicator.\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank;\n",
    "    int data = 0;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        data = 100;\n",
    "        printf(\"Process %d broadcasting data: %d\\n\", rank, data);\n",
    "    }\n",
    "    \n",
    "    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "    printf(\"Process %d received data: %d\\n\", rank, data);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73abeae6-f451-44e6-ae9c-d6667ccadc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting broadcasting.c\n"
     ]
    }
   ],
   "source": [
    "%%file broadcasting.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank;\n",
    "    int data = 0;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        data = 100;\n",
    "        printf(\"Process %d broadcasting data: %d\\n\", rank, data);\n",
    "    }\n",
    "    \n",
    "    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "    printf(\"Process %d received data: %d\\n\", rank, data);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cccce9a-155a-4afc-94e3-e1344dc1b031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 3 received data: 100\n",
      "Process 0 broadcasting data: 100\n",
      "Process 0 received data: 100\n",
      "Process 1 received data: 100\n",
      "Process 2 received data: 100\n"
     ]
    }
   ],
   "source": [
    "!mpicc broadcasting.c -o broadcasting\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf653c-0984-48ca-bac5-fd1629c5868e",
   "metadata": {},
   "source": [
    "### 10.3 Example: Gathering Data Using `MPI_Gather`\n",
    "Each process sends a value to a root process, which collects all values.\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    int local_value = rank * 10;\n",
    "    int gathered_values[size];\n",
    "    \n",
    "    MPI_Gather(&local_value, 1, MPI_INT, gathered_values, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        printf(\"Gathered values: \");\n",
    "        for (int i = 0; i < size; i++) {\n",
    "            printf(\"%d \", gathered_values[i]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4289e5b-0009-4302-abbb-58ba7db20a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mpi_gather.c\n"
     ]
    }
   ],
   "source": [
    "%%file mpi_gather.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    int local_value = rank * 10;\n",
    "    int gathered_values[size];\n",
    "    \n",
    "    MPI_Gather(&local_value, 1, MPI_INT, gathered_values, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        printf(\"Gathered values: \");\n",
    "        for (int i = 0; i < size; i++) {\n",
    "            printf(\"%d \", gathered_values[i]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe14b2f-c7a7-4825-ac8e-c596481bfc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered values: 0 10 20 30 \n"
     ]
    }
   ],
   "source": [
    "!mpicc mpi_gather.c -o mpi_gather\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./mpi_gather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cd773-43c5-4a22-aff2-650f66d5911e",
   "metadata": {},
   "source": [
    "### 10.4 Example: Reducing Values Using `MPI_Reduce`\n",
    "`MPI_Reduce` applies an operation (sum, max, min, etc.) across all processes and returns the result to the root.\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    int local_value = rank + 1;\n",
    "    int sum;\n",
    "    \n",
    "    MPI_Reduce(&local_value, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        printf(\"Total sum: %d\\n\", sum);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a910df-7085-4922-b254-2aa74151d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mpi_reduce.c\n"
     ]
    }
   ],
   "source": [
    "%%file mpi_reduce.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    int local_value = rank + 1;\n",
    "    int sum;\n",
    "    \n",
    "    MPI_Reduce(&local_value, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        printf(\"Total sum: %d\\n\", sum);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "878de6cd-ff47-471b-b3d0-133f663a20cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum: 10\n"
     ]
    }
   ],
   "source": [
    "!mpicc mpi_reduce.c -o mpi_reduce\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./mpi_reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad8c62-4c2c-4347-a25e-c074f998218b",
   "metadata": {},
   "source": [
    "### 🎯 Exercise 3\n",
    "Modify the `MPI_Reduce` example to find the **maximum** value among all ranks using `MPI_MAX`.\n",
    "\n",
    "This concludes the **Collective Communication** section. Next, we will explore **Advanced MPI Concepts**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a93cd02b-a92a-4548-beda-9625edabd164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exercise_3.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_3.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    printf(\"TODO implement me!\\n\");\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc99132-a592-4725-b49f-18c5fef841f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_3.c -o exercise_3\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./exercise_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af20ba-8f51-42cc-b032-55ed9b488ec1",
   "metadata": {},
   "source": [
    "### 11. MPI Derived Data Types and Communicators\n",
    "\n",
    "MPI allows users to define **custom data types** for efficient message passing and to create **new communicators** for better process organization.\n",
    "\n",
    "---\n",
    "### 11.1 MPI Derived Data Types\n",
    "By default, MPI supports basic data types (`MPI_INT`, `MPI_FLOAT`, `MPI_DOUBLE`, etc.), but for complex data structures, **derived data types** can be created.\n",
    "\n",
    "#### Creating a Struct Data Type\n",
    "Example: Sending a struct with an `id` and `value` field.\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "typedef struct {\n",
    "    int id;\n",
    "    double value;\n",
    "} Data;\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    int rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    Data my_data;\n",
    "    if (rank == 0) {\n",
    "        my_data.id = 42;\n",
    "        my_data.value = 3.14;\n",
    "        MPI_Send(&my_data, 1, MPI_BYTE, 1, 0, MPI_COMM_WORLD);\n",
    "        printf(\"Process %d sent data: id=%d, value=%.2f\\n\", rank, my_data.id, my_data.value);\n",
    "    } else if (rank == 1) {\n",
    "        MPI_Recv(&my_data, 1, MPI_BYTE, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        printf(\"Process %d received data: id=%d, value=%.2f\\n\", rank, my_data.id, my_data.value);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "#### Using `MPI_Type_create_struct`\n",
    "For better portability, it is recommended to use the `MPI_Datatype` struct. For example:\n",
    "```c\n",
    "MPI_Datatype MPI_DATA_TYPE;\n",
    "int block_lengths[2] = {1, 1};\n",
    "MPI_Aint offsets[2];\n",
    "offsets[0] = offsetof(Data, id);\n",
    "offsets[1] = offsetof(Data, value);\n",
    "MPI_Datatype types[2] = {MPI_INT, MPI_DOUBLE};\n",
    "MPI_Type_create_struct(2, block_lengths, offsets, types, &MPI_DATA_TYPE);\n",
    "MPI_Type_commit(&MPI_DATA_TYPE);\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a363bbd3-753c-4ee1-b430-1f6a9f3cfbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting struct.c\n"
     ]
    }
   ],
   "source": [
    "%%file struct.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "typedef struct {\n",
    "    int id;\n",
    "    double value;\n",
    "} Data;\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    int rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    Data my_data;\n",
    "    if (rank == 0) {\n",
    "        my_data.id = 42;\n",
    "        my_data.value = 3.14;\n",
    "        MPI_Send(&my_data, 1, MPI_BYTE, 1, 0, MPI_COMM_WORLD);\n",
    "        printf(\"Process %d sent data: id=%d, value=%.2f\\n\", rank, my_data.id, my_data.value);\n",
    "    } else if (rank == 1) {\n",
    "        MPI_Recv(&my_data, 1, MPI_BYTE, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        printf(\"Process %d received data: id=%d, value=%.2f\\n\", rank, my_data.id, my_data.value);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76c60391-0891-4a03-9990-c8c1fb2d07f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 sent data: id=42, value=3.14\n",
      "Process 1 received data: id=42, value=0.00\n"
     ]
    }
   ],
   "source": [
    "!mpicc struct.c -o struct\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./struct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dbbace-8348-4489-bc49-1e7a1f202065",
   "metadata": {},
   "source": [
    "### 11.2 MPI Communicators\n",
    "Communicators define **groups of processes** that can communicate. By default, all processes belong to `MPI_COMM_WORLD`, but custom communicators allow fine-grained control.\n",
    "\n",
    "#### Creating a New Communicator\n",
    "Example: Splitting MPI_COMM_WORLD into two groups.\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, color;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    color = rank % 2; // Create two groups (even, odd ranks)\n",
    "    MPI_Comm new_comm;\n",
    "    MPI_Comm_split(MPI_COMM_WORLD, color, rank, &new_comm);\n",
    "    \n",
    "    int new_rank;\n",
    "    MPI_Comm_rank(new_comm, &new_rank);\n",
    "    printf(\"Old Rank: %d, New Rank: %d, Group: %d\\n\", rank, new_rank, color);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "#### Explanation:\n",
    "- `MPI_Comm_split()` creates **two new communicators** based on `color` (even/odd ranks).\n",
    "- Each new group has its own rank assignment (`new_rank`).\n",
    "- This allows better communication **within subgroups**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1010ea37-b062-4fd3-a096-fb4d17b7539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting communicator.c\n"
     ]
    }
   ],
   "source": [
    "%%file communicator.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, color;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    color = rank % 2; // Create two groups (even, odd ranks)\n",
    "    MPI_Comm new_comm;\n",
    "    MPI_Comm_split(MPI_COMM_WORLD, color, rank, &new_comm);\n",
    "    \n",
    "    int new_rank;\n",
    "    MPI_Comm_rank(new_comm, &new_rank);\n",
    "    printf(\"Old Rank: %d, New Rank: %d, Group: %d\\n\", rank, new_rank, color);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24717545-2dcd-4b62-9b3d-7f67c7e4fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Rank: 1, New Rank: 0, Group: 1\n",
      "Old Rank: 2, New Rank: 1, Group: 0\n",
      "Old Rank: 3, New Rank: 1, Group: 1\n",
      "Old Rank: 0, New Rank: 0, Group: 0\n"
     ]
    }
   ],
   "source": [
    "!mpicc communicator.c -o communicator\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./communicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672f1f0-dec6-4c8b-867e-34df939394a3",
   "metadata": {},
   "source": [
    "### 🎯 **Exercise**\n",
    "Modify the **derived data type example** to create an `MPI_Type_create_struct()` and send/receive data properly using the new type.\n",
    "\n",
    "This concludes **MPI Derived Data Types and Communicators**. Next, we will explore **Advanced MPI Concepts**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69d634c2-7ac6-4d75-b252-a9cbcd546964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exercise_4.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_4.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    printf(\"TODO implement me!\\n\");\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fba9638-365e-4d08-8cc5-a77b6717cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_4.c -o exercise_4\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./exercise_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2bb0d-60bb-4cb1-acf3-9e3a20f17892",
   "metadata": {},
   "source": [
    "### 12. Hands-on Exercises for MPI\n",
    "\n",
    "To reinforce MPI concepts, here are several hands-on exercises covering communication, collective operations, and derived data types.\n",
    "\n",
    "---\n",
    "### 12.1 Exercise 5: Basic Point-to-Point Communication\n",
    "**Task:** Implement an MPI program where:\n",
    "- Process 0 sends an integer to Process 1.\n",
    "- Process 1 receives it and prints the value.\n",
    "\n",
    "**Code:**\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        int data = 42;\n",
    "        MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
    "        printf(\"Process 0 sent data %d to Process 1\\n\", data);\n",
    "    } else if (rank == 1) {\n",
    "        int received_data;\n",
    "        MPI_Recv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        printf(\"Process 1 received data %d from Process 0\\n\", received_data);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45410de9-7263-43c9-8598-99884eaa6f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing exercise_5.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_5.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        int data = 42;\n",
    "        MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
    "        printf(\"Process 0 sent data %d to Process 1\\n\", data);\n",
    "    } else if (rank == 1) {\n",
    "        int received_data;\n",
    "        MPI_Recv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        printf(\"Process 1 received data %d from Process 0\\n\", received_data);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d532a1c9-24ba-49bf-9154-299b6b5de4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1 received data 42 from Process 0\n",
      "Process 0 sent data 42 to Process 1\n"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_5.c -o exercise_5\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./exercise_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33c0f5-953a-4fd9-8aef-2ed288770fbc",
   "metadata": {},
   "source": [
    "### 12.2 Exercise 6: Collective Communication using `MPI_Bcast`\n",
    "**Task:** Modify the program so that:\n",
    "- Process 0 initializes an integer variable.\n",
    "- All processes receive the same value using `MPI_Bcast`.\n",
    "\n",
    "**Hint:** Use `MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d677443-bdb7-4325-b585-9356bc43270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exercise_6.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_6.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    printf(\"TODO implement me!\\n\");\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fa171f8-6725-40ca-9ace-39bb44fcb48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_6.c -o exercise_6\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./exercise_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619dd9d-37d4-4ed5-aeda-d646b246f4c1",
   "metadata": {},
   "source": [
    "### 12.3 Exercise 7: Summation using `MPI_Reduce`\n",
    "**Task:** Implement an MPI program where each process:\n",
    "- Computes a local sum based on its rank.\n",
    "- Uses `MPI_Reduce` to compute the total sum at Process 0.\n",
    "\n",
    "**Code:**\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    int local_value = rank + 1;\n",
    "    int total_sum;\n",
    "    \n",
    "    MPI_Reduce(&local_value, &total_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        printf(\"Total sum: %d\\n\", total_sum);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8c7678a-16f3-4000-90d6-19482be0d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exercise_7.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_7.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    int local_value = rank + 1;\n",
    "    int total_sum;\n",
    "    \n",
    "    MPI_Reduce(&local_value, &total_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "    \n",
    "    if (rank == 0) {\n",
    "        printf(\"Total sum: %d\\n\", total_sum);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f36fb05-ff07-4415-9491-6b223514e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum: 10\n"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_7.c -o exercise_7\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./exercise_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fefea-9f5f-4887-8ddd-83d03d61e0f4",
   "metadata": {},
   "source": [
    "### 12.4 Exercise 8: Custom Data Type Communication\n",
    "**Task:**\n",
    "- Define a custom struct with an `id` and a `value`.\n",
    "- Use `MPI_Type_create_struct` to send and receive the struct between processes.\n",
    "\n",
    "**Hint:**\n",
    "- Use `MPI_Type_create_struct()` to define a derived type.\n",
    "- Use `MPI_Send` and `MPI_Recv` to send/receive struct data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67e9fc10-10f5-408f-b5c8-3a97668b6a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing exercise_8.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_8.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    printf(\"TODO implement me!\\n\");\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa85369a-03a9-452f-8603-b07cae34a4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_8.c -o exercise_8\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./exercise_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f44a6-b136-4455-bf68-93e7e32aa401",
   "metadata": {},
   "source": [
    "### 🎯 Bonus Exercise: Ring Communication\n",
    "Modify the program so that:\n",
    "- Each process sends data to the **next process** in a ring.\n",
    "- The last process sends back to process 0.\n",
    "\n",
    "This concludes the **MPI Hands-on Exercises** section. Happy coding! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90df63ac-7a2f-463f-bb87-27d77c7a6ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing exercise_9.c\n"
     ]
    }
   ],
   "source": [
    "%%file exercise_9.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    printf(\"TODO implement me!\\n\");\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3709b91a-c094-4e80-be02-66e0f8d597c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n",
      "TODO implement me!\n"
     ]
    }
   ],
   "source": [
    "!mpicc exercise_9.c -o exercise_9\n",
    "!mpiexec --allow-run-as-root --oversubscribe  -np 4 ./exercise_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c2ac2-e943-4925-931a-4fb5b26e7cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c079200-e194-4888-abc8-39a0a1e99738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ffc12-4c2b-4115-b24c-a66d1fccb771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664bf3b-8dbf-4690-bcfe-b0bdf9b81438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be051ab-eb2e-4076-9987-cce77930f7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
